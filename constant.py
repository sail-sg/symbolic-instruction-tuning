OPENAI_API_KEY = "<<YOUR_OPENAI_API_KEY>>"
# specify the maximum length of the input during inference
MAX_LENGTH = 2048
# specify the maximum number of tokens in the generation
MAX_TOKENS = 128
